{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten,BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emocion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>uso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emocion                                             pixels       uso\n",
       "0  emotion                                             pixels     Usage\n",
       "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
       "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
       "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
       "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
       "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 16\n",
    "filename = '../Datos/fer2013.csv'\n",
    "label_map = ['Enfado', 'Asco', 'Miedo', 'Alegria', 'Tristeza', 'Sorpresa', 'Neutral']\n",
    "names=['emocion','pixels','uso']\n",
    "df=pd.read_csv(filename,names=names, na_filter=False)\n",
    "im=df['pixels']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(filname):\n",
    "    # Las imagenes 48x48 en grayscale (de 0 a 255)\n",
    "    # N = 35887 (28709 de entrenamiento y 2304 de testeo)\n",
    "    Y_train = []\n",
    "    X_train = []\n",
    "    Y_test = []\n",
    "    X_test = []\n",
    "    \n",
    "    first = True\n",
    "    uso = 'Training\\n'\n",
    "    for line in open(filname):\n",
    "        #This condition skips the first condition\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            condition = str(row[2])\n",
    "            if condition == uso:\n",
    "                Y_train.append(int(row[0]))\n",
    "                X_train.append([int(p) for p in row[1].split()])\n",
    "            else:\n",
    "                Y_test.append(int(row[0]))\n",
    "                X_test.append([int(p) for p in row[1].split()])\n",
    "                \n",
    "    X_train, Y_train = np.array(X_train)/255.0 , np.array(Y_train)\n",
    "    X_test, Y_test = np.array(X_test)/255.0 , np.array(Y_test)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= getData(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = X_train.shape[0]\n",
    "N_test = X_test.shape[0]\n",
    "X_train = X_train.reshape(N_train, 48, 48,1)\n",
    "X_test = X_test.reshape(N_test, 48, 48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode output\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "class_num = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(5,5),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation= 'relu'))\n",
    "model.add(Conv2D(64,(5,5),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation= 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128,(5,5),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation= 'relu'))\n",
    "model.add(Conv2D(128,(5,5),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation= 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation = 'relu'))\n",
    "model.add(Conv2D(256,(3,3),input_shape=X_train.shape[1:],padding = 'same', strides = 1, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2028, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(class_num, activation='softmax'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 48, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              9438208   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2028)              2078700   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 2028)              8112      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 14203     \n",
      "=================================================================\n",
      "Total params: 13,149,143\n",
      "Trainable params: 13,142,143\n",
      "Non-trainable params: 7,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "449/449 [==============================] - 1303s 3s/step - loss: 2.0611 - accuracy: 0.2629 - val_loss: 3.5211 - val_accuracy: 0.1746\n",
      "Epoch 2/100\n",
      "449/449 [==============================] - 1321s 3s/step - loss: 1.6970 - accuracy: 0.3658 - val_loss: 3.2148 - val_accuracy: 0.1920\n",
      "Epoch 3/100\n",
      "449/449 [==============================] - 1319s 3s/step - loss: 1.5108 - accuracy: 0.4341 - val_loss: 2.1004 - val_accuracy: 0.2609\n",
      "Epoch 4/100\n",
      "449/449 [==============================] - 1381s 3s/step - loss: 1.3496 - accuracy: 0.4906 - val_loss: 2.3194 - val_accuracy: 0.3140\n",
      "Epoch 5/100\n",
      "449/449 [==============================] - 1316s 3s/step - loss: 1.2290 - accuracy: 0.5366 - val_loss: 1.5356 - val_accuracy: 0.4058\n",
      "Epoch 6/100\n",
      "449/449 [==============================] - 1316s 3s/step - loss: 1.1334 - accuracy: 0.5698 - val_loss: 1.5702 - val_accuracy: 0.4961\n",
      "Epoch 7/100\n",
      "449/449 [==============================] - 1323s 3s/step - loss: 1.0775 - accuracy: 0.5932 - val_loss: 1.4330 - val_accuracy: 0.4858\n",
      "Epoch 8/100\n",
      "449/449 [==============================] - 1327s 3s/step - loss: 1.0143 - accuracy: 0.6203 - val_loss: 1.2440 - val_accuracy: 0.5344\n",
      "Epoch 9/100\n",
      "449/449 [==============================] - 1327s 3s/step - loss: 0.9314 - accuracy: 0.6539 - val_loss: 1.4449 - val_accuracy: 0.5137\n",
      "Epoch 10/100\n",
      "449/449 [==============================] - 1337s 3s/step - loss: 0.8640 - accuracy: 0.6762 - val_loss: 1.2476 - val_accuracy: 0.5729\n",
      "Epoch 11/100\n",
      "449/449 [==============================] - 1339s 3s/step - loss: 0.7964 - accuracy: 0.7062 - val_loss: 1.5377 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "449/449 [==============================] - 1335s 3s/step - loss: 0.7358 - accuracy: 0.7296 - val_loss: 1.2648 - val_accuracy: 0.5775\n",
      "Epoch 13/100\n",
      "449/449 [==============================] - 1337s 3s/step - loss: 0.6648 - accuracy: 0.7578 - val_loss: 1.6112 - val_accuracy: 0.5332\n",
      "Epoch 14/100\n",
      "449/449 [==============================] - 1334s 3s/step - loss: 0.5909 - accuracy: 0.7844 - val_loss: 1.4621 - val_accuracy: 0.5619\n",
      "Epoch 15/100\n",
      "449/449 [==============================] - 1330s 3s/step - loss: 0.5108 - accuracy: 0.8140 - val_loss: 1.6343 - val_accuracy: 0.5575\n",
      "Epoch 16/100\n",
      "449/449 [==============================] - 1339s 3s/step - loss: 0.4832 - accuracy: 0.8236 - val_loss: 2.2789 - val_accuracy: 0.5467\n",
      "Epoch 17/100\n",
      "449/449 [==============================] - 1331s 3s/step - loss: 0.4492 - accuracy: 0.8375 - val_loss: 1.7452 - val_accuracy: 0.5833\n",
      "Epoch 18/100\n",
      "449/449 [==============================] - 1329s 3s/step - loss: 0.4020 - accuracy: 0.8549 - val_loss: 2.4936 - val_accuracy: 0.4735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x217cd286bc8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "optimizer = 'adam'\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "np.random.seed(16)\n",
    "cb =  [es]\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=64, callbacks = cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
